{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1333fa59",
   "metadata": {
    "id": "1333fa59"
   },
   "source": [
    "\n",
    "# Training‑Free Prompting (Three‑Step) — Two Versions\n",
    "\n",
    "This notebook implements the exact three-step method in your paper figure:\n",
    "\n",
    "1. **Explain** the idiom in the **target language** (default: English) → *explanation / true meaning*\n",
    "2. **Literal translation** (word‑by‑word) into English\n",
    "3. **Natural idiomatic translation**, combining (1) + (2)\n",
    "\n",
    "We provide **two versions**:\n",
    "\n",
    "- **Version A (Paper Step 3 only):** Use the CSV's `true_meaning` and `literal_translation` for steps (1) and (2), then run step (3) to produce the final idiomatic translation.\n",
    "- **Version B (Fully LLM‑driven):** Ask the LLM to produce steps (1) and (2), then run step (3).\n",
    "\n",
    "Both versions save results to CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92532179",
   "metadata": {
    "id": "92532179",
    "outputId": "ce230028-1ce0-4bb5-8e8f-5699988ded31"
   },
   "outputs": [],
   "source": [
    "\n",
    "# (Optional) If needed:\n",
    "%pip install --quiet openai pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7088fa11",
   "metadata": {
    "id": "7088fa11"
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475d3823",
   "metadata": {
    "id": "475d3823"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os, json, re, hashlib, pathlib, asyncio\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Any, Optional\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- Paths ---\n",
    "INPUT_CSV = \"petci_chinese_english_improved.csv\"\n",
    "OUT_A     = \"version_A_results.csv\"      # Uses CSV meanings/literals + Step 3\n",
    "OUT_B     = \"version_B_results.csv\"      # Full LLM: Steps 1 + 2 + 3\n",
    "\n",
    "# --- Model / Inference ---\n",
    "MODEL = os.getenv(\"GPT5_MODEL\", \"gpt-5-mini\")\n",
    "TARGET_EXPLANATION_LANGUAGE = \"English\"  # change to \"Chinese\" or others if needed\n",
    "\n",
    "# Ensure your OpenAI key is available:\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "\n",
    "CACHE_DIR = pathlib.Path(\"./cache_three_step\")\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "@dataclass\n",
    "class InferenceConfig:\n",
    "    model: str = MODEL\n",
    "    top_p: float = 1.0\n",
    "    seed: Optional[int] = None\n",
    "    system_prompt: str = \"You are a precise bilingual translator. Output compact text, no extra commentary.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c45d35d",
   "metadata": {
    "id": "0c45d35d"
   },
   "source": [
    "## Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f950c23f",
   "metadata": {
    "id": "f950c23f",
    "outputId": "cb050760-2c44-412d-f12f-d2c0d5c95361"
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_idioms(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if \"src\" not in df.columns:\n",
    "        raise ValueError(\"CSV must include a 'src' column.\")\n",
    "    if \"true_meaning\" not in df.columns:\n",
    "        df[\"true_meaning\"] = None\n",
    "    if \"literal_translation\" not in df.columns:\n",
    "        df[\"literal_translation\"] = None\n",
    "    return df\n",
    "\n",
    "df = load_idioms(INPUT_CSV)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480ef060",
   "metadata": {
    "id": "480ef060"
   },
   "source": [
    "## GPT‑5 Call Helper (with disk cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823508ba",
   "metadata": {
    "id": "823508ba"
   },
   "outputs": [],
   "source": [
    "\n",
    "def _cache_key(payload: Dict[str, Any]) -> str:\n",
    "    return hashlib.sha256(json.dumps(payload, sort_keys=True, ensure_ascii=False).encode()).hexdigest()\n",
    "\n",
    "def call_gpt5(user_content: str, cfg: InferenceConfig) -> str:\n",
    "    payload = {\n",
    "        \"model\": cfg.model,\n",
    "        \"top_p\": cfg.top_p,\n",
    "        \"seed\": cfg.seed,\n",
    "        \"system\": cfg.system_prompt,\n",
    "        \"user\": user_content,\n",
    "    }\n",
    "    key = _cache_key(payload)\n",
    "    f = CACHE_DIR / f\"{key}.json\"\n",
    "    if f.exists():\n",
    "        return json.loads(f.read_text())[\"text\"]\n",
    "\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI()\n",
    "    resp = client.chat.completions.create(\n",
    "        model=cfg.model,\n",
    "        messages=[\n",
    "            {\"role\":\"system\",\"content\":cfg.system_prompt},\n",
    "            {\"role\":\"user\",\"content\":user_content},\n",
    "        ],\n",
    "        top_p=cfg.top_p,\n",
    "        seed=cfg.seed\n",
    "    )\n",
    "    text = resp.choices[0].message.content.strip()\n",
    "    f.write_text(json.dumps({\"text\": text}, ensure_ascii=False))\n",
    "    return text\n",
    "\n",
    "CFG = InferenceConfig()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c938c06",
   "metadata": {
    "id": "3c938c06"
   },
   "source": [
    "## Three Prompts (matching the paper steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ecfb3a",
   "metadata": {
    "id": "43ecfb3a"
   },
   "outputs": [],
   "source": [
    "\n",
    "PROMPT_STEP1_EXPLAIN = \"\"\"\n",
    "Explain the meaning of the following Chinese idiom in {lang}.\n",
    "- Audience: educated readers; be concise (<= 2 sentences).\n",
    "- Do not translate word-by-word; provide the **idiomatic sense**.\n",
    "\n",
    "Idiom: {idiom}\n",
    "\"\"\".strip()\n",
    "\n",
    "PROMPT_STEP2_LITERAL = \"\"\"\n",
    "Provide a **literal, word-by-word** English translation for the following Chinese idiom.\n",
    "- Keep it terse and faithful to each component.\n",
    "- No commentary, just the literal gloss.\n",
    "\n",
    "Idiom: {idiom}\n",
    "\"\"\".strip()\n",
    "\n",
    "PROMPT_STEP3_NATURAL = \"\"\"\n",
    "Produce a **natural English idiomatic translation** given:\n",
    "(1) An idiom explanation (idiomatic meaning) and\n",
    "(2) A literal word-by-word gloss.\n",
    "\n",
    "Rules:\n",
    "- Output a single short English phrase/sentence that a native speaker would actually say.\n",
    "- Prefer clarity and naturalness over literalness.\n",
    "- No extra commentary.\n",
    "\n",
    "Idiom: {idiom}\n",
    "Explanation: {explanation}\n",
    "Literal: {literal}\n",
    "Result:\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa88b0ea",
   "metadata": {
    "id": "aa88b0ea"
   },
   "source": [
    "## Version A — Use CSV (steps 1 & 2 from file) → Run Step 3 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4295bc7",
   "metadata": {
    "id": "f4295bc7",
    "outputId": "7b0db740-c20b-4062-e316-0df6be7aacf0"
   },
   "outputs": [],
   "source": [
    "\n",
    "def version_A_run(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        idiom = str(r[\"src\"])\n",
    "        explanation = str(r[\"true_meaning\"]) if pd.notna(r[\"true_meaning\"]) else \"\"\n",
    "        literal = str(r[\"literal_translation\"]) if pd.notna(r[\"literal_translation\"]) else \"\"\n",
    "\n",
    "        # Step 3 prompt\n",
    "        p3 = PROMPT_STEP3_NATURAL.format(idiom=idiom, explanation=explanation, literal=literal)\n",
    "        final = call_gpt5(p3, CFG)\n",
    "\n",
    "        rows.append({\n",
    "            \"src\": idiom,\n",
    "            \"explanation_used\": explanation,\n",
    "            \"literal_used\": literal,\n",
    "            \"final_translation\": final\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "res_A = version_A_run(df)\n",
    "res_A.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80839831-fea6-4556-bb27-3125b6eced6f",
   "metadata": {
    "id": "80839831-fea6-4556-bb27-3125b6eced6f"
   },
   "source": [
    "## Version A Fast— Use CSV (steps 1 & 2 from file) → Run Step 3 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd25c84d-e1f9-4861-b342-ebdb6f0c2f11",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "945edc8f8d344feda7929416fb1ce678"
     ]
    },
    "id": "cd25c84d-e1f9-4861-b342-ebdb6f0c2f11",
    "outputId": "ba932e11-606c-4305-e764-b07dfa7b9961"
   },
   "outputs": [],
   "source": [
    "# helper: run blocking call_gpt5 in a thread\n",
    "async def _run_gpt(p3, cfg):\n",
    "    loop = asyncio.get_running_loop()\n",
    "    return await loop.run_in_executor(None, call_gpt5, p3, cfg)\n",
    "\n",
    "async def _worker(row):\n",
    "    idiom = str(row[\"src\"])\n",
    "    explanation = str(row[\"true_meaning\"]) if pd.notna(row[\"true_meaning\"]) else \"\"\n",
    "    literal = str(row[\"literal_translation\"]) if pd.notna(row[\"literal_translation\"]) else \"\"\n",
    "\n",
    "    p3 = PROMPT_STEP3_NATURAL.format(\n",
    "        idiom=idiom,\n",
    "        explanation=explanation,\n",
    "        literal=literal,\n",
    "    )\n",
    "\n",
    "    final = await _run_gpt(p3, CFG)\n",
    "\n",
    "    return {\n",
    "        \"src\": idiom,\n",
    "        \"explanation_used\": explanation,\n",
    "        \"literal_used\": literal,\n",
    "        \"final_translation\": final,\n",
    "    }\n",
    "\n",
    "async def version_A_run_parallel(df: pd.DataFrame, concurrency: int = 8) -> pd.DataFrame:\n",
    "    # limit how many GPT calls happen at once\n",
    "    sem = asyncio.Semaphore(concurrency)\n",
    "    tasks = []\n",
    "\n",
    "    for row in df.to_dict(orient=\"records\"):\n",
    "        async def go(row=row):\n",
    "            async with sem:\n",
    "                return await _worker(row)\n",
    "        tasks.append(go())\n",
    "\n",
    "    results = []\n",
    "    for coro in tqdm(asyncio.as_completed(tasks),\n",
    "                     total=len(tasks),\n",
    "                     desc=\"Translating idioms\"):\n",
    "        results.append(await coro)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "res_A = await version_A_run_parallel(df)\n",
    "res_A.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb10606a",
   "metadata": {
    "id": "fb10606a"
   },
   "source": [
    "## Version B — Full LLM (steps 1 & 2 via model) → Run Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328bfcfe",
   "metadata": {
    "id": "328bfcfe",
    "outputId": "e0766538-f683-4a2d-8c8c-f4ba63a77cc2"
   },
   "outputs": [],
   "source": [
    "\n",
    "def step1_explain(idiom: str, lang: str = TARGET_EXPLANATION_LANGUAGE) -> str:\n",
    "    p = PROMPT_STEP1_EXPLAIN.format(idiom=idiom, lang=lang)\n",
    "    return call_gpt5(p, CFG)\n",
    "\n",
    "def step2_literal(idiom: str) -> str:\n",
    "    p = PROMPT_STEP2_LITERAL.format(idiom=idiom)\n",
    "    return call_gpt5(p, CFG)\n",
    "\n",
    "def step3_natural(idiom: str, explanation: str, literal: str) -> str:\n",
    "    p = PROMPT_STEP3_NATURAL.format(idiom=idiom, explanation=explanation, literal=literal)\n",
    "    return call_gpt5(p, CFG)\n",
    "\n",
    "def version_B_run(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        idiom = str(r[\"src\"])\n",
    "\n",
    "        # Step 1 & 2 generated by LLM\n",
    "        explanation_gen = step1_explain(idiom)\n",
    "        literal_gen     = step2_literal(idiom)\n",
    "\n",
    "        # Step 3\n",
    "        final = step3_natural(idiom, explanation_gen, literal_gen)\n",
    "\n",
    "        rows.append({\n",
    "            \"src\": idiom,\n",
    "            \"explanation_gen\": explanation_gen,\n",
    "            \"literal_gen\": literal_gen,\n",
    "            \"final_translation\": final\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "res_B = version_B_run(df)\n",
    "res_B.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5417066b",
   "metadata": {
    "id": "5417066b"
   },
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debd4427",
   "metadata": {
    "id": "debd4427",
    "outputId": "33c178c8-273d-49a2-da31-733be86fbc9e"
   },
   "outputs": [],
   "source": [
    "\n",
    "res_A.to_csv(OUT_A, index=False)\n",
    "#res_B.to_csv(OUT_B, index=False)\n",
    "print(\"Saved:\")\n",
    "print(\" - Version A →\", OUT_A)\n",
    "#print(\" - Version B →\", OUT_B)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (hw1)",
   "language": "python",
   "name": "hw1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
